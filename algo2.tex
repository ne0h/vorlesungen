\chapter{Algorithmen II}

Zusammenfassung der Vorlesung "`Algorithmen II"' aus dem Wintersemester 2014.\footnote{\url{http://geom.ivd.kit.edu/ws14_algo2.php}}


\section{Flussmaximierung}

\subsection{Flussnetzwerke}
\textbf{Ziel:} Berechnung des maximalen Flusses.

\subsubsection{Bestandteile}
\begin{itemize}
	\item Graph mit Quelle \(q\) und Senke \(s\): \(G(V,E)\) mit \(E \subset V^2\)
	\item Kapazitätsfunktion \(k : V^2 \rightarrow \mathbb{R}_{+0}\), wobei \(\forall e \in V^2 \setminus E: k(e) = 0\)
\end{itemize}

\subsubsection{Flüsse}
Ein Fluss in F ist eine Funktion \(f:V^2\rightarrow\mathbb{R}\) mit den Eigenschaften:
\begin{enumerate}
	\item \(f \leq k\)
	\item \(\forall x,y \in V : f(x,y) = -f(y,x)\)
	\item \(\forall x \in V \setminus \{ q,s \}: 0 = \sum f(x,V) := \sum_{y\in V} f(x,y)\)
\end{enumerate}
\paragraph{Flusserhalt} Wegen (2) bedeutet (3), dass in jeden Knoten außer \(q\) und \(s\) soviel positiver Fluss rein- wie rausfließt.

\subsubsection{Bemerkungen}
\begin{itemize}
	\item Der maximale Fluss ist die Summe der von der Quelle ausgehenden / bei der Senke ankommenden genutzen Kapazitäten / der minimale Schnitt durch den Graphen
	\item Der negative Fluss soll lediglich die Darstellung vereinfachen und ist ansonsten uninteressant
	\item Mehrere Flussnetzwerke können zu einem Flussnetzwerk zusammengefasst werden (mit unendlichen Zu- und Abflüssen)
	\item Residualgraph: Der Graph der Restkapazität
\end{itemize}


\subsection{Algorithmus von Ford und Fulkerson}
\begin{itemize}
	\item \textbf{Algorithmus}
	\begin{enumerate}
		\item Setze die Flüsse an allen Kanten gleich Null
		\item Solange es einen Pfad von \(q\) nach \(s\) gibt, erhöhe diesen maximal
	\end{enumerate}
	\item Terminiert Ford-Fulkerson, ist \(f\) maximal, da es keinen weiteren Pfad \(q \rightarrow^{*} s\) gibt
	\item Aufwand: \(\mathcal{O}(|E| \cdot max\{W_f | f~Fluss~in~F\})\), denn ein Pfad \(q \rightarrow^{*} s\) kann in \(|E|\) Schritten gefunden werden
\end{itemize}
\input{algo2/algo_ford-fulkerson}


\subsection{Algorithmus von Edmonds und Karp}
\begin{itemize}
	\item Idee: Anwendung von Ford-Fulkerson immer längs eines kürzesten Pfades (Breitensuche)
	\item Terminiert auch für beliebige reelle Kapazitäten
	\item In jedem Schritt verliert \(E_f\) eine Kante
	\item Aufwand: \(\mathcal{O} (|E|^2 \cdot |V|)\)
\end{itemize}


\subsection{Präfluss-Pusch-Methode}
Jeder Knoten erhält zusätzlich eine Höhe und ein Reservoir, um vorübergehend beliebig viel Fluß speichern zu können.

\subsubsection{Operationen}

\paragraph{\(PUSCH(x,y)\)}
\begin{itemize}
	\item \textbf{Bedingungen}
	\begin{itemize}
		\item Überschuss bei \(x\) vorhanden: \(u(x) > 0, x \in V \setminus \{q,s\}\)
		\item \(x\) liegt höher als \(y\): \(h(x) - h(y) \leq 1\)
	\end{itemize}
	\item \textbf{Algorithmus}
	\begin{enumerate}
		\item Ermittle den Abfluss aus Überschuss und Restkapazität: \(min\{u(x), k_f(x,y)\}\)
		\item Erhöhe den Fluss auf der Kante \((x,y)\)
		\item Aktualisiere die Überschusswerte an \(x\) und \(y\)
	\end{enumerate}
\end{itemize}
\input{algo2/algo_praeflusspusch_pusch}

\paragraph{\(LIFTE(x)\)}
\begin{itemize}
	\item \textbf{Bedingungen}
	\begin{itemize}
		\item Der Knoten ist weder \(q\) noch \(s\)
		\item Überschuss bei \(x\) vorhanden
		\item \(x\) kann nur geliftet werden, wenn kein Pfad \(y \rightarrow x\) eine höhere Restkapazität aufweist: \(h(x) < h(y)\)
	\end{itemize}
	\item \textbf{Algorithmus}
	\begin{enumerate}
		\item Erhöhe \(x\): \(h(x) = 1 + min\{h(y)\}\)
	\end{enumerate}
\end{itemize}
\input{algo2/algo_praeflusspusch_lifte}

\paragraph{Durchführung}
\begin{enumerate}
	\item \textbf{Initialisiere}
	\begin{enumerate}
		\item Alle Knoten außer \(q\) wird \(h=0\) zugewiesen (\(h(q) = |V|)\)
		\item Alle von \(q\) ausgehenden Pfade bekommen die Kapazität nach \(k(x,y)\) zugewiesen, alle anderen Pfade \(0\)
	\end{enumerate}
	\item Solange es eine beliebige, erlaubte Operation gibt, führe diese aus
\end{enumerate}
\input{algo2/algo_praeflusspusch}

\subsubsection{Laufzeit}
\[\mathcal{O} (|V|^2 \cdot |E|)\]


\subsection{Move-to-Front-Algorithmus}
Durch eine strukturierte Abarbeitung der Operationen wird \textit{Präfluss-Pusch} beschleunigt.

\begin{itemize}
	\item Idee: Strukturiertes Entladen der Knoten
	\item Die Nachbarn von \(x\) werden über eine invertierte Liste verwaltet
	\item \((x,y) \in E\) heißt \textit{puschbar}, falls \(k_f(x,y) \geq 0\) und \(h(x)-h(y)\geq 1\)
	\item Die Knoten werden über eine Liste verwaltet, in der \(x\) vor \(y\) auftritt, falls \((x,y)\) \textit{PUSCHBAR} ist
	\item Geliftete Knoten werden an die Spitze der Listen gesetzt
\end{itemize}

\subsubsection{Operationen}
\input{algo2/algo_an-die-spitze_leere}
\text{}\\
\input{algo2/algo_an-die-spitze}

\subsubsection{Laufzeit}
\[\mathcal{O}(|V|^3)\]



\section{Zuordnungsprobleme}
\textbf{Ziel:} Verteilung verschiedener Aufgaben auf eine Gruppe von Personen mit unterschiedlichen Fähigkeiten.

\subsection{Paaren in bipartiten Graphen}
\begin{itemize}
	\item Eine Paarung beinhaltet zwei Knoten exklusiv
	\item Eine Paarung heißt maximal, wenn es keine bessere Paarung gibt
	\item Maximale Paarung über Flußmaximierung: Ergänzung des bipartiten Graphs um Quelle und Senke
\end{itemize}


\subsection{Paaren in allgemeinen Graphen}
Sei \(G=(V,E)\) ein Graph mit einer Paarung \(P\) und einer maximalen Paarung \(Q\).

\subsubsection{Symmetrische Differenz}
\[D:=(P\setminus Q) \cup (Q \setminus P)\]
Die Kanten dieser Wege liegen alternierend in \(P\) und \(Q\) \(\rightarrow\) Zyklen haben eine gerade Länge.

\subsubsection{Definition}
Es gibt \(k= |Q|-|P|=|Q\setminus (P \cap Q)| - |P\setminus (P \cap Q)|\) Wege, auf denen \(P\) vergrößert werden kann. Die Endkanten liegen beiden \(\in Q\).

\subsubsection{Folgerung}
Man kann eine maximale Paarung durch sukzessive Vergrößerungen finden.

\paragraph{Algorithmus zur Vergößerung}
\begin{enumerate}
	\item Suche \((x,y) \in E\), wobei \(x\) mit keinem \(z\in V\) gepaart
	\item Setze \((x,y)\) durch Breitensuche zu einem alternierden Weg \(W\) ungerade Länge fort
\end{enumerate}
\input{algo2/algo_paare}

\subsubsection{Blüten}
\begin{itemize}
	\item Zu Problemen kommt es bei sogenannten Blüten
	\item Lösung: Man schrumpft die Blüten ohne ihren Stil zu einem Knoten
\end{itemize}

\subsubsection{Aufwand der Suche nach vergrößernden Wegen}
\[\mathcal{O}(\sqrt{|V|} \cdot |E|)\]


\subsection{Maximal gewichtete Paarung}
\textbf{Gesucht:} Maximal gewichtete Paarung eines ungerichteten Graphen:
\[\Gamma(P) := \Sigma \gamma (P)\]

\subsubsection{Annahme}
Man kann eine maximal gewichtete Paarung finden, indem eine maximal gewichtete Kante iterativ durch einen vergrößernden Weg zu einer nächstgrößeren Paarung vergrößert wird.

\paragraph{Aufwand}
\[\mathcal{O}(min\{|V|^3, |V| \cdot |E| \cdot log|V|\})\]



\section{Stochastische Algorithmen}

\subsubsection{Begriffe}
\begin{itemize}
	\item Las-Vegas-Algorithmus: Randomisierter Algorithmus, der immer ein korrektes Ergebnis liefert, wenn er terminiert.\footnote{\url{http://de.wikipedia.org/wiki/Las-Vegas-Algorithmus}}
	\item Monte-Carlo-Algorithmus: Randomisierte Algorithmen, die mit einer nach oben beschränkten Wahrscheinlichkeit ein falsches Ergebnis liefern dürfen. Dafür sind sie im Vergleich zu deterministischen Algorithmen häufig effizienter.\footnote{\url{http://de.wikipedia.org/wiki/Monte-Carlo-Algorithmus}}
\end{itemize}

\subsection{Erwartungswert}
Der Erwartungswert einer Zufallsvariablen beschreibt die Zahl, die die Zufallsvariable im Mittel annimmt.\footnote{\url{http://de.wikipedia.org/wiki/Erwartungswert}}

\subsubsection{Sigma-Additivität}
\[\mathbb{E}\lbrack \Sigma X_i\rbrack = \Sigma E \lbrack X_i\rbrack\]


\subsection{Quicksort}
\begin{itemize}
	\item Sortieren durch stochastisches Teilen
	\item Aufwandsabschätzung anhand der durchgeführten Vergleiche
\end{itemize}
\input{algo2/algo_quicksort}


\subsection{Minimaler Schnitt}

\subsubsection{Definitionen}
\begin{itemize}
	\item Ereignisse: Die Teilmengen einer Stichprobenmenge
	\item Bedingte Wahrscheinlichkeit: \(Pr \lbrack E_1 | E_2 \rbrack := \frac{Pr\lbrack E_1 \cap E_2 \rbrack}{Pr\lbrack E_2 \rbrack} \)
	\item Multigraph: Kanten können mehrfach vorkommen
\end{itemize}

\subsubsection{Algorithmus zur Berechnung des Schnitts}
\input{algo2/algo_schnitt}



\section{Technik der Spieltheorie}
Aufwandsabschätzung von Las-Vegas-Algorithmen nach unten.

\subsection{Nullsummenspiele}
\begin{itemize}
	\item Eine Tabelle gibt die Gewinne für \(A\) und die Verlust für \(B\) an
	\item Bedingung: \(Gewinn(A) + Gewinn(B) = 0\)
	\item Definiert durch eine \(n \times m\) Matrix \(M\)
\end{itemize}

\subsubsection{Strategien}
\begin{itemize}
	\item Bei \(reinen~Strategien\) legt sich der Spieler eindeutig auf eine bestimmte Aktion fest, daher der Einheitsvektor \(e\)
	\item Die Zeilen von \(M\) heißen Strategien von \(A\), die Spalten von \(M\) heißen Strategien von \(B\)
	\item Zeile \(i\) ist eine optimale Strategie für \(A\), falls sie den Mindestgewinn: \(min_j~M_{ij}\) von \(A\) maximiert
	\item Spalte \(j\) ist eine optimale Strategie für \(B\), falls sie den Maximalverlust: \(max_i~M_{ij}\) von \(B\) minimiert
	\item Wählen beide optimale Strategien: \(max_i~min_j~M_{ij} \leq \mathbb{E} \lbrack Gewinn(A) \rbrack \leq min_j~max_i~M_{ij}\)
\end{itemize}


\subsection{MiniMax-Theorem}
Das Min-Max-Theorem ist ein grundlegendes Lösungskonzept in der Spieltheorie. Die Minimierung der gegnerischen Maximal-Auszahlung beider Spieler steht im Vordergrund und ist Ursache für die Entstehung der Bezeichnung \textit{Min-Max-Theorem}.\footnote{\url{http://de.wikipedia.org/wiki/Min-Max-Theorem}}

\subsubsection{Definitionen}
\begin{enumerate}
	\item \(p := \lbrack p_1,...,p_m \rbrack^T \) bezeichnet die \textit{gemischte Strategie} von \(A\)
	\item \(q := \lbrack q_1,...,q_n \rbrack^T \) bezeichnet die \textit{gemischte Strategie} von \(B\)
	\item Erwartungswert des Gewinns von \(A\): \(\mathbb{E}\lbrack Gewinn(A) \rbrack = p^T \cdot M \cdot q\)
	\item Optimale Strategie von \(A\): \(min_q~(p^T \cdot M \cdot q)\)
	\item Wählen \(A\) und \(B\) optimale Strategien, gilt:\\ \(max_p~min_q~(p^T \cdot M \cdot q) \leq E \lbrack Gewinn(A) \rbrack \leq min_q~max_p~(p^T \cdot M \cdot q)\)
\end{enumerate}

\subsubsection{Von-Neumanns-MiniMax-Theorem}
\[max_p~min_q~(p^T \cdot M \cdot q) = min_q~max_p~(p^T \cdot M \cdot q)\]

\paragraph{Definition}
\text{}\\ \(W := max_p~min_q~(p^TMq)\) heißt \textit{Wert} und ein Paar \((p,q)\) optimaler Strategien \textit{Lösungen} des Spiels \(M\) mit gemischten Stratgien.

\subsubsection{Loomis Satz}
\[max_p~min_j~(p^T \cdot M \cdot e_j) = min_q~max_i~(e_i^T \cdot M \cdot q)\]

Für ein festes \(p\) wird \(p^T \cdot M \cdot q\) minimiert, wenn die j-te Koordinate von \(p^T \cdot M\) minimal ist.


\subsection{Yaos Technik}
Verwendung des MiniMax-Theorems zur Laufzeitabschätzung von stochastischen Algorithmen für ein Problem \(P\) (\textit{B} kann als stochastischer Algorithmus aufgefasst werden):
\(B\) wählt einen Algorithmus \(A \in \{A_1,...,A_m\}\) und \(A\) wählt eine Eingabe \(E \in \{E_1,...,E_n\}\).

Sei \(M_{ij}\) die Laufzeit \(A_j(E_i)\), dann gilt:

\begin{itemize}
	\item Worst-case-Laufzeit von \(A\): \(max_i~M_{ij}\)
	\item Deterministische Laufzeit von \(A\): \(min_j~max_i~M_{ij}\)
	\item Best-case-Laufzeit von \(A\): \(min_j~M_{ij}\)
	\item Stochastische Komplexität (Laufzeit) von \(A\) bzgl. \(P\): \(max_i~min_j~M_{ij} =: K_s\). Würde \(B\) immer ein schnellstes \(A_j\) für die Eingabe wählen, entspräche diese Wahl einem stochastischen Algorithmus it optimaler Laufzeit \(K_s\).
	\item Erwartungswert der Laufzeit: \(\mathbb{E}\lbrack Laufzeit \rbrack: \sum_{ij} p_i \cdot M_{ij} \cdot q =: p^T \cdot M \cdot q\)
	\item Verteilungskomplexität: \(K_v := max_p~min_q~(p^T \cdot M \cdot q)\)
\end{itemize}

\subsubsection{Folgerung}
\[K_s \leq K_v \leq K_d\]

\subsubsection{MiniMax-Theorem von Yao}
\[\forall p,q: min_j~(p^T \cdot M \cdot e_j) \leq K_v \leq max_i~(e_i^T \cdot M \cdot q)\]
Hiermit kann die worst-case-Laufzeit aller stochastischer Algorithmen durch die Laufzeit des schnellsten deterministischen Algorithmus nach unten abgeschätzt werden.


\subsection{Spielbaumauswertung}
Ein binärer Spielbaum ist ein balancierter Binärbaum gerader Höhe \(2k\) mit Knotenwert \(x \in \{0,1\}\) und den Kindknoten \(y \in \{0,1\}\) und \(z \in \{0,1\}\). Es gilt:
\[Wert(x) = Wert(y) \downarrow Wert(z)\]

Aus \((a \downarrow b) \downarrow (c \downarrow d) = (a \vee b) \wedge (c \vee d)\) folgt, dass die Nicht-Blattknoten auf gerader Höhe den Minima und bei ungerader Höhe den Maxima der Werte ihrer Kindknoten entsprechen. Das entspricht einem Spiel, bei dem zwei Spieler abwechselnd ihren Gewinn maximieren.

\subsubsection{Bestimme den Wurzelwert aus den Blattwerten}
\input{algo2/algo_wert}

Falls \(w=1\) kann direkt \(0\) zurückgegeben werden, ohne weiter zu traversieren.



\section{Algorithmen für geometrische Probleme}

\subsection{Binäre Zerlegung der Ebene}

\subsubsection{Vorgehen}
Teile die affine Ebene \(A\) anhand einer Halbgeraden \(S_1\) in die Ebenen \(A_0\) und \(A_1\), wobei die Halbgeraden in beide Richtungen unbegrenzt verlängert werden, bis sie auf eine bereits zur Zerlegung verwendete Halbgerade treffen. Fahre rekursiv fort.

\subsubsection{Raumzerlegungsbaum}
Die entstandenen Aufteilungen lassen sich über einen binären Raumzerlegungsbaum darstellen. Anwendung beispielsweise in der Computergrafik (Maleralgorithmus: Übermalen von Flächen, um die Tiefenberechnung zu sparen).
Ziel dabei: Möglichst kleine RZBs mit wenigen Zerlegungen.


\subsection{Binäre Zerlegung des Raums}
Folgender Algorithmus erzeugt binäre RZBs für den \(\mathbb{R}^3\):
\text{}\\
\input{algo2/algo_brz}

\subsubsection{Satz}
\(Z\) bezeichnet die Anzahl der von \(BRZ\) erzeugten Teilsegmente der \(P_i\). Es gilt:
\[\mathbb{E}\lbrack Z \rbrack \in \mathcal{O}(n^2)\]
Ein planares Polygon sei durch \(k\) Geraden zerlegt \(\rightarrow\) Anzahl der Randgebiete \(\in \mathcal{O}(k)\).


\subsection{Konvexe Hüllen}

Wir fassen den \(\mathbb{R}^3\) als affinen Raum \(A\) auf und bezeichnen dessen Elemente als Punkte und ihre Differenzen als Vektoren. Die konvexe Hülle einer Teilmenge ist die kleinste konvexe Menge, die die Ausgangsmenge enthält\footnote{\url{http://de.wikipedia.org/wiki/Konvexe_H\%C3\%BClle}} (alle weiteren Elemente liegen in dem Raum, den die konvexe Hülle aufspannt).

\subsubsection{Begriffe}
\begin{itemize}
	\item Konvexe Menge \(M\): Die Verbinungsstrecke zweier beliebiger Punkte im Polygon liegt komplett in diesem (keine Einbuchtungen)
	\item Konvexkombination: Linearkombination, wenn alle Koeffizienten \(\in I\lbrack 0,1\rbrack\) (Einheitsinterval) und \(\sum Koeffizienten = 1\)
\end{itemize}

\subsection{Dualität}

\subsubsection{Hyperebene}
Die Lösungsmenge einer linearen Gleichung \(u^T \cdot x = 1\) mit \(u \in \mathbb{R}^n\) heißt Hyperebene von \(A\), d.h.
\[u^* := \{x \in A~|u^T \cdot x = 1\}.\]
\(u \in A\) wird der zu \(u^*\) duale Punkt und \(x^*\) die zum Punkt \(x\) \textit{duale Hyperebene} genannt.

\subsubsection{Dualraum}
Der Dualraum beinhaltet alle, zu Hyperebenen dualisierten, Punkte aus \(A\).
\[A^* = \{x^*~|~x \in A\}\]

\subsubsection{Halbraum}
Die Lösung der Ungleichung
\[u^T \cdot x \leq 1, u \ne 0,\]
bildet den Halbraum \(u^{\leq}\).

\subsubsection{Folgerung}
\[x \in u^* \Leftrightarrow u \in x^*\]
\[x \in u^{\leq} \Leftrightarrow u \in x^{\leq}\]

\subsubsection{Polarmenge}
\begin{itemize}
	\item Der Menge eines Vektorraums wird eine Menge des Dualraums zugeordnet (und umgekehrt)
	\item Beinhaltet die dualen Punkte zu den Hyperebenen
	\item \(M_p = \{u~|~M \subset u^{\leq}\}\) und \(M_{pp} = \{x~|~M_p \subset x^{\leq}\}\)
	\item Konvex und abgeschlossen
\end{itemize}

\subsubsection{Berechnung der Konvexen Hülle mit Hilfe von Polarmengen}
Die Konvexe Hülle von \(M := \{p_1,...,p_i\}\) kann daher als Schnitt der Halbräume, die aus den Punkten dualisiert wurden, berechnet werden:
\[M_p \longleftarrow Schnitt~der~HRe~p_i^{\leq}.\]
Dabei bestimmen die Ecken
\[u_i := p_{i_1}^* \cap ... \cap p_{i_d}^*\]
von \(M_p\), die Schnitte von je \(d\) Ebenen der Dualmenge \(M^*\). Die Punkte \(p_{i_1},...,p_{i_d}\) spannen die Facetten von \(\lbrack M \rbrack\) auf.


\subsection{Beziehungen zwischen Knoten, Kanten und Facetten}
Die Formeln gelten nicht nur für Polyeder, sondern für beliebige geschlossene Netze mit topologischen Geschlecht \(2\), d.h. Netze, die bis auf Verbindungsformen eine Kugeloberfläche darstellen.

\subsubsection{Eulers Formel}
Für einen Polyeder mit \(v\) Knoten, \(e\) Kanten und \(f\) Seiten gilt:
\[v-e+f=2\]

\paragraph{Erweiterung des Netzes}
\begin{itemize}
	\item Hinzufügen eines Knoten, der über eine Kante mit dem Rest des Graphen verbunden ist: Die Anzahl der Ecken und Kanten steigt jeweils um eins, während die Anzahl der Flächen gleichbleibt.
	\item Hinzufügen einer Kante, die zwei existierende Knoten verbindet: Während die Anzahl der Ecken gleichbleibt, steigt die Anzahl der Flächen und Kanten jeweils um eins. 
\end{itemize}

\subsubsection{Triangulation von Polyedern}
Durch die Hinzunahme von Kanten kann ein Polyeder trianguliert werden, wodurch sich der Wert der Formel nicht ändert. Werden \(k\) Kanten hinzugefügt, gilt:
\[3(f+k) = 2(e+k)\]
Daraus folgt der mittlere Knotengrad
\[\frac{2e}{v} \leq 6\]
und dazu die mittlere Kantenzahl pro Seite
\[\frac{2e}{f} \leq 6.\]
Darüber hinaus bedeutet es, dass Konvexe Hüllen als Schnitt dualer Halbräume bestimmt werden können.


\subsection{Konstruktion Konvexer Hüllen}
Die Berechnung der Konvexen Hülle über die Punktmenge ist vergleichsweise aufwendig. Da die Berechnung von Ebenenschnitten deutlich günstiger ist, bietet es sich an, alle Punkte der Ausgangsmenge zu dualisieren und die Ebenenschnitte zu berechnen. Danach können die Ebenen, welche die Konvexe Hülle aufspannen, wieder zu Punkten dualisiert werden.

\paragraph{Datenstruktur zur Speicherung der Polyeder}
Darstellung durch eine Liste der Ecken des Polyeders, wobei die Listenelemente (die Ecken) jeweils folgendes enthalten:
\begin{itemize}
	\item Eine Liste von Zeigerpaaren auf die Nachbarecken im Uhrzeigersinn
	\item Die vorderen Elemente der Zeigerpaare verweisen auf die Nachbarecken
	\item Die hinteren Elemente verweisen auf das Zeigerpaar der Nachbarecke, die auf die Ecke zurückverweisen
\end{itemize}
Mithilfe dieser Polyederdarstellung lassen sich alle Kanten und Facetten mit einem Aufwand \(\in \mathcal{O}(|Ecken|)\) ausgeben.
\text{}\\\\
\input{algo2/algo_konvexe-huelle}
\text{}\\
Gesamtlaufzeit \(\in \mathcal{O}(nlogn)\).



\section{Bewegungsplanung bei unvollständiger Information}
\begin{itemize}
	\item Suche nach einer Lösung, über die auch zur Laufzeit nur Teilwissen bekannt ist
	\item Qualität der Ausgabe ist interessanter als die Laufzeit
	\item Es kann sein, dass keine oder keine eindeutige Lösung existiert
\end{itemize}


\subsection{Ausweg aus einem Labyrinth}
Wir betrachten ein Labyrinth \(L\) und einen Roboter \(R\) mit Tastsensor und Drehwinkelmessgerät.
\text{}\\
\input{algo2/algo_pledge}

\subsubsection{Satz}
Seien \(K_1,...,K_n, n \in \mathbb{N} \cup \{0,\infty\}\) die Kanten des Wegs von \(R\).
\begin{enumerate}
	\item Drehwinkel \(\phi\) immer \(\geq 0\)
	\item Der Weg von \(R\) kann sich berühren oder aber nicht kreuzen
	\item Immer wenn \(R\) eine Kante erneut abläuft berührt sich der Weg: \(\phi_{l+m}=\phi_l+2\pi\)
\end{enumerate}


\subsection{Zum Ziel in unbekannter Umgebung}
Gegeben sind \(P_1,...P_n\) disjunkte Polygone, ein Roboter \(r\), ein Startpunkt \(s\) und ein Ziel \(z\).
\text{}\\
\input{algo2/algo_wanze}
\text{}\\
\textbf{Wanze terminiert:} Umläuft \(R\) zuerst \(P_i\) und dann \(P_j\) gilt:
\[dist(z,P_i) > dist(z,P_j).\]
\(R\) umläuft daher jedes Polygon höchstens einmal und findet \(z\) spätestens nach Umlaufen aller \(P_i\).

\subsubsection{Universelles Steuerwort}
Jedes Steuerwort \(w \in \{z,l,r\}^*\) entspricht einer Bewegung, die auf \(s\) angewendet den Endpunkt \(w(s)\) ergibt, der dieser Bewegung entspricht. Beispiel: \(w = zr^3zl^3z\)

\paragraph{Satz}
Es gibt ein universelles Steuerwort \(w\), das für alle Startpunkte innerhalb einer spezifischen Szene zum gegebenen Ziel \(z\) führt \(\rightarrow \) da \(r\) alle endlichen Steuerworte erzeugen kann, erreicht er spätestens mit dem universellen sein Ziel. Ein Zielkompass genügt also zur Zielfindung.

\paragraph{Finden des universellen Steuerwortes}
Operationen, die nicht durchführbar sind, werden ignoriert.
\begin{enumerate}
	\item Berechne das Steuerwort für einen beliebigen Polygoneckpunkt
	\item Für alle weiteren Eckpunkte: Erweitere das bestehende Steuerwort sukszessive durch Konkatenation weiterer Schritte
	\item Ergänze \(lz\) für Startpunkte, die keine Polygoneckpunkte sind
\end{enumerate}


\subsection{Behälterproblem}
\textbf{Ziel:} Zerlege eine Folge \(A := (a_1,...,a_m)\) in möglichst wenig Teilfolgen \(A_j\) mit einer bestimmten Größe \(h\) (dieses Problem ist NP-hart).
\text{}\\\\
\input{algo2/algo_firstfit}
\text{}\\\\
Die Laufzeit ist in \(\mathcal{O}(nlogn)\). Während \textit{FIRST-FIT} packt, ist immer höchstens ein Behälter halb voll oder leerer, da sonst ein zusätzlicher Behälter gebraucht werden würde. Benötigt \textit{FIRST-FIT} also \(k\) Behälter, werden auch bei einer optimalen Packung mindestens
\[k_{opt} > \frac{k}{2}\]
gebraucht. Somit ist
\[m < 2k_{opt}.\]

\subsubsection{Kompetitivität}
Größe der Lösung eines Problems \(P\)
\begin{itemize}
	\item Optimaler Algorithmus: \(k_{opt}: \epsilon \rightarrow \mathbb{N}\)
	\item Korrekter Algorithmus \(A\): \(k_A: \epsilon \rightarrow \mathbb{N}\)
\end{itemize}
Es gilt:
\[k_A \leq a+c\cdot k_{opt}~(a,c \in \mathbb{R})\]
\(c\) bezeichnet den Kompetivitätsfaktor des Algorithmus.


\subsection{Türsuche}
\textbf{Ziel:} Finde die Tür an einer langen, unüberschaubaren Wand.
\text{}\\
\input{algo2/algo_tuersuche-1}

\paragraph{Kompetivität}
Obiger Algorithmus ist nicht kompetitiv. Wird Zeile 6 durch \(i = 2i\) erweitert, ist der insgesamt zurückgelegte Weg bei einer maximalen Entfernung \(d=2^{n+\delta}\) der Tür vom Startpunkt
\[w \leq \sum_{i=0}^{n+1} 2^i+d \leq 2^{n+3+\delta}+d \leq 9 \cdot 2^{n+\delta}\]
entfernt \(\rightarrow Kompetitivitaetsfaktor=9\).


\subsection{Sternsuche}
Verallgemeinerung der Türsuche.

\paragraph{Ziel} Finden des Ziels \(z\) vom Startpunkt \(s\) aus mit Hilfe von \(m\) wachsenden Halbgeraden.
\text{}\\\\
\input{algo2/algo_sternsuche}

\paragraph{Kompetivität}
Im schlechtesten Fall liegt \(z\) auf \(H_{k~mod~m}\rightarrow d = f_k+\delta\). Damit gilt:
\[w = 2\sum_{i=0}^{k+m-1} f_i + d = 2 \sum\left(\frac{m}{m-1}\right)^i+d < 2(m-1)\left(\frac{m}{m-1}\right)^{k+m}+d,\]
\[\frac{w}{d} \leq \frac{2(m-1)}{f_k}\left(\frac{m}{m-1}\right)^{k+m}+1=2(m-1)\left(\frac{m}{m-1}\right)^m+1=2m\left(\frac{m}{m-1}\right)^{m-1}+1.\]
Daher ist beispielsweise für \(m=2\) der Kompetitivitätsfaktor \(c=9\).


\subsection{Suche in Polygonen}
Es gibt keine kompetitive Strategie.

\subsubsection{Definitionen}
\begin{itemize}
	\item Ein Polygon \(P\) heißt geschlossen, wenn gilt \(p_m = p_1\).
	\item Ein Polygon \(P\) heißt einfach, wenn kein Punkt von \(P\) in zwei Kanten liegt, mit Ausnahme der Ecken.
\end{itemize}

\subsubsection{Vorgehen}
\begin{itemize}
	\item Es gibt nur einen kürzesten Weg von \(s\) zu \(z\)
	\item Die kürzesten Wege von \(s\) zu den Ecken von \(P\) bildet der \textit{Baum der kürzesten Wege} von \(P\) und \(s\)
\end{itemize}

\subsubsection{Baum der kürzesten Wege}
\begin{itemize}
	\item Die kürzesten Wege \(s\) zu den Ecken von \(P\) bilden den Baum der kürzesten Wege (BkW) von \(P\) und \(s\)
	\item Absuchen der Wege zu den Blättern per Sternsuche
	\item Speichern der bereits erreichten Punkte als Zwischenstopps für spätere Punkte
\end{itemize}



\section{Lineare Programmierung}
\textbf{Ziel:} Maximierung linearer Funktionen mit linearen Nebenbedingungen; beispielsweise zur Bestimmung des maximalen Flusses in einem Netzwerk oder um das MiniMax-Theorem zu beweisen.

\subsection{Lineares Programm}
Die lineare Ungleichung
\[y := \upsilon^T \cdot x + u \geq 0\]
beschreibt den Halbraum mit Normalenvektor \(\upsilon\). Die Nebenbedingungen
\[y_i := a_i^T \cdot x + a_i \geq 0,~i = 1,...,l\]
bilden ein konvexes Polygon \(s\), das in der linearen Programmierung \textit{Simplex} genannt wird. Das gesuchte Maximum, das durch die Nebenbedingungen begrenzt wird, befindet sich innerhalb dieses Simplex.

\subsubsection{Normalform des linearen Programms}
\textbf{Ziel:} Maximierung einer linearen Zielfunktion über dem Simplex \(s\):

\[z = c^T\cdot \bar{y} + c \stackrel{!}{=} max\]
\[y' \geq 0\]
\[y'' = B \cdot y' + b \geq 0\]

\[\begin{array}{c|ccc|c|}
	& & y' \geq 0 & & 1 \\
	\hline
	& & & & \\
	y''= & & B & & b \\
	& & & & \\
	\hline
	z= & & c^T & & c \\
	\hline
\end{array}\]
\(c\) wird maximiert.


\subsection{Eckentausch}
\textbf{Ziel:} Um \(z\) zu maximieren, machen wir sukzessive neue \(y_i\) zu neuen Koordinaten, so dass der Ursprung von Ecke zu Ecke wandert und der Wert von \(z\) im Ursprung wächst.
\\\\
\textbf{Vorgehen}: Tausche immer eine Koordinate von \(y'\) mit einer von \(y''\).
\[\begin{pmatrix}
	a_{11}v_1 & ... &a_{1n}v_n & u_1\\
	.   &		.	& .   & . \\
	.   &		.	& .   & . \\
	.   &		.	& .   & . \\
	a_{m1}v_1 & . & a_{mn}v_n & u_m
\end{pmatrix}\]
Ist \(a_{rs} \ne 0\) können \(u_r\) und \(v_s\) getauscht werden. Ein beliebiges \(a_{rs}\) fungiert als Pivotelement. 
\text{}\\
\input{algo2/algo_simplex_austausch}


\subsection{Der Simplexalgorithmus}
\textbf{Ausgangspunkt:} Ein lineares Programm in Normalform
\[\begin{array}{c|ccc|c|}
	& x_1 & ... & x_n & 1 \\
	\hline
	y_1= & b_{11} & ... & b_{1n} & b_1 \\
	\vdots & \vdots & & \vdots & \vdots \\
	y_m= & b_{m1} & ... & b_{mn} & b_n \\
	\hline
	z= & c_1 & ... & c_n & c \\
	\hline
\end{array}\]
\paragraph{Vorgehen} Iteratives Tauschen von \(y_r\) mit \(x_s\).
\text{}\\\\
\input{algo2/algo_simplex}


\subsection{Berechnung der Normalform}
\begin{itemize}
	\item Für die Überführung eines linearen Programms in die Normalform muss eine Ecke des Simplex zum Ursprung gemacht werden
	\item Da es nur endlich viele Ecken gibt, wird eine Lösung nach endlich vielen Schritten gefunden
	\item Problem: Im Allgemeinen sind die Ecken des Simplex nicht bekannt, aber einen oder mehrere zulässige Punkte, die durch Translation zum Ursprung gemacht werden können
	\item \textbf{Iteratives Vorgehen}
	\begin{enumerate}
		\item Tauschen von \(y_r\) mit \(x_s\) auf der Hauptdiagonalen. Der Ursprung wandert auf einer Koordinatenachse
		\item Gedankliches Streichen der getauschten Zeile
	\end{enumerate}
\end{itemize}


\subsection{Flussmaximierung}
Die Suche nach einem maximalen Fluss in einem Flussnetzwerk kann als lineares Programm angesehen werden.

\paragraph{Gegeben} Gerichteter Graph mit Kapazitätsbeschriftung.
Daraus ergibt sich das lineare Programm:
\[z = x_1 + x_2 = max!\]
Nebenbedingungen:
\begin{itemize}
	\item \textbf{Flusserhaltung}
	\begin{itemize}
		\item Für jeden Knoten die Summe der aus- und eingehenden Flüsse: z.B. \(x_1-x_3-x_4 \geq 0\)
		\item Für jeden Knoten die negierten aus- und eingehenden Flüsse: z.B. \(-x_1+x_3+x_4 \geq 0\)
	\end{itemize}
	\item \textbf{Kapazitätsbeschränkung}
	\begin{itemize}
		\item Für alle Kanten die Beschränkung des Flusses: z.B. \(5-x_1 \geq 0\)
		\item An allen Kanten muss der Fluss positiv sein: z.B. \(x_1 \geq 0\)
	\end{itemize}
\end{itemize}


\subsection{Duale lineare Programme}
Das lineare Programm
\[x \geq 0\]
\[B\cdot x + b \geq 0\]
\[c^T \cdot x + c = max!\]
wird durch die Matrix \(\mathbb{B} := \begin{pmatrix} B & b \\ c^T & c\end{pmatrix}\) repräsentiert. Durch Eckentausch kann sie auf eine Normalform \(\overline{\mathbb{B}}\) gebracht werden.

\subsubsection{Dualitätsgesetz}
Das lineare Programm
\[y \geq 0\]
\[B^T \cdot y + c \leq 0\]
\[b^T \cdot y + c = min!\]
hat die Normalform \(\overline{\mathbb{B}}^T\), die Lösung \(\overline{y}=0\) und den Minimalwert \(\overline{c}\).
\paragraph{Definition} Die beiden linearen Programme heißen dual zueinander.
\paragraph{Bemerkung} Das zweite Programm kann umgeschrieben und mit \textit{SIMPLEX} gelöst werden. Gleichzeitig löst man damit das erste Programm. Es ist das Lösen des \textit{primalen Programms} in dualer Form.


\subsection{Beweis des MiniMax-Theorems}
Mit Hilfe des Dualitätssatzes für lineare Programme kann das MiniMax-Theorem
\[max_{x \in W_M}~min_{y \in W_n}~x^TAy = min_{y \in W_n}~max_{x \in W_m}~x^T A y\]
bewiesen werden. Auf Grund des SIMPLEX-Algorithmus ist es äquivalent zu
\[max_x~min_i~x^T A e_j = min_y~max_i~e_i^T A y\]

\subsubsection{Linke Seite}
Auf der linken Seite wird
\[x_0 := min_i~x^T A e_j\]
maximiert. Da \(x_0\) mit \(x\) wächst, erhält man das lineare Programm
\\\\
\[\begin{array}{|cc|c|}
x & x_1 & 1 \\
\hline
A^T & -b & 0 \\
-a^T & 0 & 1 \\
\hline
0^T & 1 & 0 \\
\hline
\end{array}\]

\subsubsection{Rechte Seite}
Analog wird die rechte Seite
\[max_i~e_i^T A y\]
minimiert. Man erhält das lineare Programm
\\\\
\[\begin{array}{|cc|c|}
y & x_0 & 1 \\
\hline
A & -a & 0 \\
-b^T & 0 & 1 \\
\hline
0^T & 1 & 0 \\
\hline
\end{array}\]

\subsubsection{Folgerung}
Da die rechte Seite dual zur linken Seite, folgt das MiniMax-Theorem.


\subsection{Ausgleichen mit der Maximumsnorm}
Sei
\[Ax = a\]
ein überbestimmtes Gleichungssystem, d.h. für alle \(x\) ist das Residuum
\[r := \begin{bmatrix} r_1 \\ \vdots \\ r_n \end{bmatrix} := Ax - a \ne 0.\]
\paragraph{Ziel} Minimieren von
\[r := \parallel r \parallel_{\infty} := max_i~|r_i|\]
mit Hilfe eines linearen Programms
\[-A\overline{x} + ax_0 + e \geq 0\]
\[A\overline{x} - ax_0 + e \geq 0\]
\[x_0 = max!\]

\subsubsection{Vorgehen zur Berechnung}
\textbf{Gegeben:} Lineares, überbestimmtes Gleichungssystem
\begin{enumerate}
	\item Aufstellen des linearen Programms
	\begin{enumerate}
		\item Formulieren der Nebenbedingungen und der negierten Nebenbedingungen
		\item Nebenbedingungen im linearen Programm gleich \(1\) setzen
	\end{enumerate}
	\item Berechnen des Maximums nach dem \textit{SIMPLEX}-Algorithmus
	\item Berechnung von \(x_1\) aus \(r\) (\(z = x_0\))
\end{enumerate}


\subsection{Aufwand}
\begin{itemize}
	\item Worst-Case-Laufzeit: \(\Omega(m^{\frac{n}{2}})\)
	\item Laufzeit in der Praxis: \(\mathcal{O}(m^2n)\)
	\item Lineare Programme sind NP-hart (Überführung in Rücksackproblem möglich)
\end{itemize}



\section{Zufallsgesteuerte Optimierung}

\subsection{Definitionen}

\subsubsection{Optimierungsaufgabe}
Eine Optimierungsaufgabe besteht aus
\begin{itemize}
	\item einem Suchraum \(Q\), der Teil eines Zustandraumes \(Z\) ist,
	\item einer Bewertungsfunktion (Kostenfunktion) \(c:Z \rightarrow \mathbb{R}\), die jedem Zustand \(q\) seine Kosten zuordnet,
	\item Nebenbedingungen.
\end{itemize}
\textbf{Gesucht:} Ein \(q \in Q\) mit minimalen oder maximalen Kosten.

\subsubsection{Kombinatorische Optimierungsaufgabe}
Eine Optimierungsaufgabe heißt kombinatorisch, wenn der Suchraum \(Q\) diskret ist.

\subsubsection{Globales/Lokales Optimum}
\begin{itemize}
	\item \(q \in Q\) heißt \textit{globales Optimum}, wenn für alle anderen Lösungen \(p \in Q\) gilt: \(c(q) \leq c(p)\)
	\item \(q \in Q\) heißt \textit{lokales Optimum}, wenn für alle Nachbarn \(p \in Q\) von \(q\) gilt: \(c(q) \leq c(p)\)
\end{itemize}


\subsection{Gradientenverfahren}
\begin{itemize}
	\item Verfahren anschaulich: Der Algorithmus nähert sich schrittweise, nur mit Kenntnis der nächsten Nachbarn dem Maximum (Minimum). Ist kein Aufstieg (Abstieg) mehr möglich, so terminiert er
	\item Problem: Eventuell ist nur ein lokales Extremum erreicht
	\item \textbf{Nicht anwendbar, wenn}
	\begin{itemize}
		\item die Berechnung der Nebenbedingung unangemessen aufwendig ist,
		\item lokale Optima auf dem Weg zum globalen Optimum liegen.
	\end{itemize}
\end{itemize}


\subsection{Suchverfahren}
Definition eines Suchbaums, der beginnend bei seinem Anfangszustand durchsucht werden kann.

\subsubsection{Beispiel: Handlungsreisender}
\begin{itemize}
	\item Gesucht: Eine möglichst günstige Rundreise
	\item Prinzip: Iterative Auswahl des "`besten"' Kindknotens
	\item \textbf{Probleme}
	\begin{itemize}
		\item Bestimmung des "`besten"' Nachfolgers kann sehr aufwendig sein
		\item Eventuell sind Rückschritte nötig, da der Weg zur optimalen Lösung nicht monoton verbessernd ist
	\end{itemize}
\end{itemize}


\subsection{Stochastische Verfahren}

\subsubsection{Probleme bisher}
\begin{itemize}
	\item Bei kombinatorischem steilsten Abstieg müssen die Kosten jeweils für alle Nachfolger berechnet werden (hoher Aufwand). Lösungsidee: Nachfolger zufällig wählen
	\item Steilster An- oder Abstieg kann zu lokalem statt globalen Optimum führen. Lösungsidee: Unter Umständen auch "`schlechtere"' Lösungen im nächsten Iterationsschritt akzeptieren
\end{itemize}

\subsubsection{Grundalgorithmus}
\input{algo2/algo_zufallsgesteuerte-optimierung_grundalgorithmus}

\subsubsection{Simuliertes Tempern}
\begin{itemize}
	\item Technik zur Züchtung von Kristallen (beim Härten von Stahl)
	\item Temperatur wird kontrolliert abgesenkt
	\item Dabei sinkt die Energie des Systems nicht monoton \(\rightarrow\) kann lokalen Extrema entkommen
\end{itemize}

\paragraph{Maximumsalgorithmus}
Gegeben sind Temperaturen \(t_1,t_2,t_3,...\) und \(K\) als obere Schranke für die maximal zu berücksichtigenden Nachbarn. Verschlechterungen werden akzeptiert, wenn die \textit{Aktzeptanzbedingung}
\[exp(\frac{c(p)-c(q)}{t_i}) > Zufallszahl \in \lbrack 0,1 \rbrack\]
gilt. Bei großen Temperaturen werden Verschlechterungen eher akzeptiert als bei kleinen (beispielsweise bei lokalen Maxima).
\text{}\\
\input{algo2/algo_simuliertes-tempern}

\subsubsection{Schwellwert-Algorithmus}
\begin{itemize}
	\item Der Schwellwert \(\sigma \geq 0\) wird regelmäßig abgesenkt
	\item Verwendung der Akzeptanzbedingung \(c(p) > c(q) - \sigma\)
	\item Anschaulich: \(\sigma\) erlaubt das kurzzeitige Abwärtsgehen nach einem lokalen Maximum. Mit fortschreitendem Aufstieg wird die Toleranz abwärts zu gehen geringer
	\item Keine Garantie, dass das globale Optimum erreicht wird
\end{itemize}

\subsubsection{Sintflut-Maximierung}
\begin{itemize}
	\item Es gibt eine untere Grenze \(F\), die nicht unterschritten werden darf
	\item \(F\) wird regelmäßig angehoben
	\item Akzeptanzbedingung \(c(p) \geq F\) ist unabhängig von \(q\)
	\item Keine Garantie, dass das globale Optimum erreicht wird
\end{itemize}

\subsubsection{Rekordjagd-Algorithmus}
\begin{itemize}
	\item Der bisher höchste Wert (Rekord) wird wird gespeichert
	\item Dieser darf nur um eine bestimmte Toleranz \(\delta\) unterschritten werden
	\item Der Rekord wird regelmäßig abgesenkt
	\item Die Akzeptanz \(c(p) \geq Rekord-\sigma\) ist unabhängig von \(q\)
	\item Keine Garantie, dass das globale Optimum erreicht wird
\end{itemize}

\subsubsection{Vergleich der Verfahren}
\begin{itemize}
	\item Beispiel Gröschels-Handlungsreisender: Bohre 442 Löcher in möglichst kurzer Zeit in eine Platine. \textbf{Der Sintflut-Algorithmus bietet die beste Lösung} (kommt der mathematisch besten Lösung am nächsten)
	\item \textbf{Feststellungen von Dueck, Scheuer und Wallmeister}
	\begin{itemize}
		\item Nur Schwellwert-Verfahren und simuliertes Tempern können aus kleinen, aber tiefen lokalen Minima entkommen
		\item Allerdings sind bei hoch-nicht-lineare Optimierungsaufgaben die Extremwerte im Allgemeinen weder markant noch tief
		\item Sintflut- und Schwellwert-Verfahren sind dem simulierten Tempern überlegen
		\item Der Sintflut-Algorithmus ist fast genauso gut wie das Schwellwert-Verfahren, nicht ganz so stabil in der Qualität der Lösungen, dafür jedoch ewas schneller
		\item \textbf{Das Schwellwert-Verfahren ist die Methode der Wahl}
		\item Bei einem reichhaltigen Sortiment von Veränderungsschritten wird besser optimiert
	\end{itemize}
\end{itemize}


\subsection{Evolutionäre Algorithmen}
\textbf{Idee:} Nachbilden des Evolutionsprinzips aus der Biologie.

\subsubsection{Einführung}
\begin{itemize}
	\item Eine \textit{Population} besteht aus \textit{Individuen}
	\item Ein \textit{Individuum} besitzt einen \textit{Genotyp} (Merkmalsvektor) \(q \in \mathbb{R}^n\) und einen \textit{Phänotyp} (Bewertung bzw. Fitness)
	\textit{Individuen} können sich fortpflanzen und ihren \textit{Genotyp} verändern (Mutation). Haben sie zwei oder mehr Eltern heißen sie \textit{Kreuzungen}, haben sie nur einen Eltern sind es \textit{Klone}
	\item Die Größe der \textit{Population} wird einigermaßen konstant gehalten, d.h. es werden immer wieder Lösungen verworfen ("`survival of the fittest"')
\end{itemize}

\subsubsection{Evolutionsstrategien}
\begin{itemize}
	\item Ein Individuum wird durch \(q \in \mathbb{R}^n\) und einen Streuungsvektor \(\sigma \in \mathbb{R}^n\) repräsentiert
	\item Nachkommen mutieren nach der Regel \(q^{(t+1)} = q^t+d\), wobei \(d\) zufällig normal- oder geometrisch verteilt ist mit Streuungsvektor \(\sigma\)
	\item \(\sigma\) kann bei der Evolution mitverändert werden
\end{itemize}

\subsubsection{Die Plus-Evolutionsstrategie}
\begin{itemize}
	\item Die Population \(Q\) ändert sich mit der Zeit \(t\), nicht aber ihre Größe \(\mu := |Q|\)
	\item Zu jedem Zeitpunkt werden \(\lambda\) Nachkommen erzeugt
	\item Die \(\mu\) Individuen mit der besten Fitness \(c(q)\) untern den \(\mu\) Eltern und \(\lambda\) Nachkommen bilden die nächste Polulation \(Q\). Die anderen \(\lambda\) Individuen sterben, Eltern können überleben
	\item Die Eltern aller Individuen werden gleichverteilt aus \(Q\) gewählt 
\end{itemize}

\subsubsection{Die Komma-Evolutionsstrategie}
\begin{itemize}
	\item Gleich der \textit{Plus-Strategie}, allerdings überleben die Eltern nicht
	\item Nur die Stärksten der Nachkommen überleben
\end{itemize}

\subsubsection{Mehrere Eltern}
\begin{itemize}
	\item Individuen können auch mehrere Eltern haben
	\item \textbf{Methoden}
	\begin{itemize}
		\item Mischen: Für jedes Merkmal wird zufällig ein Elternteil bestimmt, von dem es übernommen wird
		\item Mitteln: Für jedes Merkmal wird der Durchschnittswert der Eltern gebildet
	\end{itemize}
\end{itemize}


\subsection{Genetische Algorithmen}

\subsubsection{Prinzip}
\begin{itemize}
	\item Binäre Merkmalsvektoren, d.h. \(Q = \{0,1\}^n\)
	\item In jeder Generation erzeugen \(\mu\) Eltern \(\mu\) Nachkommen und nur diese überleben
	\item Starke Eltern paaren sich "`häufiger"' (höhere Wahrscheinlichkeit) als "`schwächere"'
\end{itemize}

\subsubsection{Ablauf}
\begin{enumerate}
	\item \textbf{Fortpflanzung}
	\begin{itemize}
		\item Jedes Individuum \(q\) wird mit der Wahrscheinlichkeit \(W(q) = \frac{c(q)}{\sum_{p \in Q}c(p)}\) Elter
		\item Die \(\mu\) Individuen erzeugen \(\mu\) Klon-Nachkommen. Nur diese überleben
	\end{itemize}
	\item \textbf{Kreuzung}
	\begin{itemize}
		\item Dann werden unter den \(\mu\) Nachkommen \(p\%\) Individuen ausgesucht, die der Kreuzung unterzogen werden
		\item Die Kreuzungspartner werden zufällig festgelegt
		\item Kreuzung per Kreuzprodukt
	\end{itemize}
	\item \textbf{Mutation:} Jedes Bit des Merkmalvektors wird mit einer sehr kleinen Mutationswahrscheinlichkeit \(p_m\) invertiert
\end{enumerate}


\subsection{Vergleich}

\subsubsection{Evolutionsstrategien}
\begin{itemize}
	\item konvergieren im Allgemeinen schneller
	\item enden öfter in lokalem Minimum
\end{itemize}

\subsubsection{Genetische Algorithmen}
\begin{itemize}
	\item bevorzugen Kreuzungen vor Mutationen
	\item spähen daher Suchraum in größeren Sprüngen aus
	\item und finden öfter ein globales Optimum
	\item konvergieren aber schlechter
\end{itemize}


\subsection{Partikel-Schwarm-Optimierung}
\textbf{Idee:} Übertragen des Verhaltens von Fisch- und Vogelschwärmen auf allgemeine Optimierung.

\subsubsection{Einführung}
Ein Schwarm besteht aus Partikeln. Zum \(i-\)ten Partikel gehören seine
\begin{itemize}
	\item Position \(p_i(t)\) im \(\mathbb{R}^n\) abhängig von der Zeit \(t\)
	\item Fitness \(f(p_i)\)
	\item Geschwindigkeit \(v_t(t) = p_t(t)-p_i(t-1)\)
\end{itemize}
Dabei ist \(f(x)\) zu optimieren.

\subsubsection{Algorithmenskizze}
\begin{itemize}
	\item Initialisiere die \(p_t(0)\) und \(v_i(0)\) zufällig
	\item Aktualisiere die nächsten Positionen, Geschwindigkeiten und Lernkonstanten
	\item Typische Werte: ca 20-40 Partikel
\end{itemize}
\input{algo2/algo_pso}

\subsubsection{Superschwarm-Optimierung}
\begin{itemize}
	\item Die Lernkonstanten können mit einem Superschwarm optimiert werden
	\item Die Position eines Superpartikels entspricht einer Parameterwahl und der Position eines einfachen Schwarms mit diesen Parametern
	\item Die Fitness der optimalen Fitness, die durch eine Partikelschwarm-Optimierung mit dieser parameterwahl erzielt wird
\end{itemize}


\subsection{Ameisen-Systeme}
\begin{itemize}
	\item Ameisen markieren ihre Wege mit Duftstoffen (Pheremonen)
	\item Kurze Wege zu Futterplätzen werden in der gleichen Zeit öfter markiert als lange
	\item Geleitet durch die Intensität der Markierung finden Ameisen die kürzesten Wege
\end{itemize}
Dies kann auf Probleme übertragen werden, in denen Pfade in Grapen zu bestimmen sind.

\subsubsection{Beispiel Rundreise}
Seien
\begin{itemize}
	\item \(\{1,...,n\}^2\) die Kantenmenge eines Graphen
	\item \(d_{ij}\) die Länge der Kante \(ij\)
	\item \(p_{ij}\) die Intensität der Pheromonmarkierung
\end{itemize}
Von \(m\) Knoten aus wird je eine Ameise auf eine Rundreise geschickt. Danach werden die \(p_{ij}\) mit der Evaporationsrate \(\rho \in \lbrack 0,1)\) neu gesetzt:
\[p_{ij} = \rho \cdot p_{ij} + \sum_k \Delta p_{ij}^k\]
\[\Delta p_{ij}^k = \begin{cases} \frac{1}{d_{ij}}, & falls~Ameise~k~Kante~ij~benutze \\ 0, & sonst \end{cases}\]
Danach suchen die Ameisen wiederholt erneut eine Rundreise, bis eine Abbruchbedingung erfüllt ist.



\section{Der De-Casteljau-Algorithmus}
Mit Unterteilungsalgorithmen lassen sich Kurven und Flächen beliebiger Gestalt erzeugen. In der Regel wird ein initiales Polygon wiederholt verfeinert und geglättet, so dass eine konvergente Polgonenfolge entsteht.

Der \textit{Algorithmus von de Casteljau} ermöglicht die effiziente Berechnung einer beliebig genauen Näherungsdarstellung von Bézierkurven durch einen Polygonzug.\footnote{\url{http://de.wikipedia.org/wiki/De-Casteljau-Algorithmus}}


\subsubsection{Bezeichnungskonvention}
\begin{itemize}
	\item \(k\): Unterteilungstiefe
	\item \(j\): Kurvenindex innerhalb der Stufe
	\item \(i\): Kontrollpunktindex innerhalb einer Teilkurve innerhalb einer Stufe 
\end{itemize}
\[p_i^{k,j}\]


\subsection{Der Algorithmus}
\textbf{Idee:} Eine Bézierkurve kann geteilt und durch zwei aneinandergesetzte Bézierkurven dargestellt werden (Endpunktinterpolation).

Der Algorithmus besteht daher aus einfachen Interpolationsschritten. Angewendet auf \(B_0^0\) ergibt das:
\[C(B_0^0,t) = B_0^1B_1^1 = b_0^0...b_n^0~b_0^n...b_n^0,\]
beziehungsweise rekursiv über \(k\) Stufen fortgesetzt:
\[C^*(B_0^0,k):=B_0^k...B_{2^k-1}^k.\]
\text{}\\
\input{algo2/algo_de-casteljau}


\subsection{Kanonische Parametrisierung}
Die durch den Unterteilungsoperator \(C^*\) erzeugten Polygone
\[B^k := B_0^k...B_{2^k-1}^k\]
konvergieren gegen eine polynomielle Kurve. Um dies zu zeigen, parametrisiert man die Polygone \(P:=p_0...p_n\) und betrachtet ihre Ableitungen.

Dazu fasst man diese als stückweise lineare Funktionen auf, die über ihren Intervallen \(\lbrack \beta_i^{k,j},\beta_{i+1}^{k,j}\rbrack\) jeweils linear sind und bestimmt sie über ihre Knoten und deren Werte.


\subsection{Differenzenpolygone}
Ein Polygon \(C^*(B,k)\) setzt sich aus \(2^k\) Polygonen zusammen. Sei \(B\) das Polygon \(b_0...b_n\), dann ist sein \textit{Differenzenpolygon} das Polygon
\[\Delta B := (b_1-b_0)...(b_n-b_{n-1}).\]

Für \(B_0B_1 := C^*(B,1)\) gilt:
\[\Delta B_0\Delta B_1 = \frac{1}{2}\cdot C^*(\Delta B,1).\]
Die Differenzen eines unterteilten Polygons lassen sich also aus den halbierten Differenzen des ursprünglichen Polygons mit Hilfe des \textit{de-Casteljau-Algorithmus} berechnen.

\subsubsection{Folgerung}
Somit gilt für \(B_1...B_{2^k} = C^*(B,k)\) ebenfalls:
\[\Delta B_1...\Delta B_{2^k} = \frac{1}{2^k}C^*(\Delta B,k)\]


\subsection{Ableitung unterteilter Polygone}
Ableitungen und Konvergenz vektorvertiger Funktionen können koordinatenweise betrachtet werden.

Unterteilt man ein Polygon \(B\) mit \(n\) Kanten \(k\)-mal mit dem \textit{de-Casteljau-Algorithmus}, erhält man die stückweise lineare Funktion
\[b(t) := L_k(B).\]
Die Ableitung \(b(t) := \frac{d}{dt}b(t)\) ist stückweise konstant, somit ist \(b^*\) eine stückweise konstante Parametrisierung des Differenzenpolygons \(n \cdot C^*(\Delta B,k)\) und kann abgeschätzt werden:
\[sup(\lbrack0,1\rbrack)~|~\dot{b}^k(t)-n\cdot L_k(\Delta B)|\in \mathcal{O}(\frac{1}{2^k})\]


\subsection{Konvergenz}
Zu jedem Polygon \(B=b_0...b_n\) gibt es ein Polygon \(L_{\infty}(B)\) vom \(Grad \leq n\), so dass
\[sup(\lbrack0,1\rbrack)~|~\dot{b}^k(t)-L_{\infty}(\Delta B)|\in \mathcal{O}(\frac{1}{2^k})\]
Damit gilt
\[\frac{d}{dt}L_{\infty}(B) = n \cdot L_{\infty}(\Delta B).\]



\section{Der Algorithmus von Lane und Riesenfeld}
Lane und Riesenfeld veröffentlichten 1980 einen Unterteilungsalgorithmus um stückweise polynomielle Kurven (Splines) zu erzeugen. Dabei handelt es sich um einen stationären Unterteilungsalgorithmus, der durch eine einzige, wiederholt anzuwendende lineare Operation beschreibar ist.

Im Gegensatz zum \textit{de-Casteljau-Algorithmus} wird der \textit{LR-Algorithmus} meist für biinfinite Kontrollpolygone
\[c_{\mathbb{Z}} := (c_i)_{i \in \mathbb{Z}} = (...~c_{-1}~c_0~c_1~...)\]
beschrieben, weil es die Darstellung vereinfacht.

Endliche Polygone können als biinfinite aufgefasst werden, bei denen nur endlich viele der Kontrollpunkte \(c_i\) von \(0\) verschieden sind.
\text{}\\\\
\input{algo2/algo_lr}


\subsection{Unterteilungsmatrizen}
Zur Analyse des LR-Algorithmus können die Koordinaten der Kontrollpolygone betrachtet werden. Es reicht somit aus, ein skalarwertiges Polygon
\[c := (...~c_{-1}~c_0~c_1~...) \in \mathbb{R}^{\mathbb{Z}}\]
zu unterteilen.

\subsubsection{Verdopplungsmatrix}
Jede Spalte wird jeweils \(2x\) auf die selbe Zeile abgebildet \(\rightarrow\) Verdopplung der Kontrollpunkte.
\[d := D c :=
	\begin{bmatrix}
		\ddots 	& 		& 				& \\
				& 1 	&				& \\
				& 1 	&				& \\
				&		& \textbf{1} 	& \\
				&		& 1 			& \\
				&		&				& \ddots
	\end{bmatrix}  c
\]

\subsubsection{Mittelungsmatrix}
Durch Addition der Nachbarn und anschließender Skalierung wird jeweils der Mittelwert berechnet.
\[Md := \frac{1}{2}
	\begin{bmatrix}
		\ddots 	& 		& 		&				&		&			\\
				& 1 	& 1		& 				&		&			\\
				& 	 	& 1		& \textbf{1} 	&		&			\\
				&		&		& 1 			& 1		&			\\
				&		&		&				&		& \ddots
	\end{bmatrix} d
\]

\subsubsection{Darstellung des Algorithmus}
Das einmal unterteilte Polygon ist \(U_nc := M^nDc\), das \(m\)-mal unterteilte \(U_n^mc\) .

Die Unterteilungsmatrizen \(U_n, n \in \mathbb{N}_0\) stellen den LR-Algorithmus dar und können durch \(n\)-fache Mittelung der Spalten einer biinfiniten Matrix \(D\) berechnet werden. Man erhält so
\[U_1 = \frac{1}{2} M^1 \cdot D = \frac{1}{2}
\begin{bmatrix}
	\ddots 	& 1 			& 				& 			\\
			& 2 			& 				& 			\\
			& 1 			& 1 			& 			\\
			& 				& 2 			& 			\\
			& 				& 1 			& \ddots 	\\
\end{bmatrix},
\]
\[U_2 = \frac{1}{4}M^2\cdot D = \frac{1}{4}
\begin{bmatrix}
	\ddots 	& 1 			& 				&			\\
			& 3 			& 				&			\\
			& 3 			& 1 			&			\\
			& 1 			& 3 			&			\\
			& 				& 3 			&			\\
			& 				& 1 			& \ddots 	\\
\end{bmatrix},
\]
und allgemein
\[U_n := \frac{1}{2^n}M^n\cdot D = \frac{1}{2^n}
\begin{bmatrix}
	\ddots 	& \vdots 		&				&			\\
			& \alpha_0		&				&			\\
			& \alpha_1		& \vdots		&			\\
			& \alpha_2		& \alpha_0		&			\\
			& \vdots		& \vdots		&			\\
			& \alpha_{n+1}	& \alpha_{n-1} 	&			\\
			& \vdots		& \alpha_n		&			\\
			&				& \alpha_{n+1}	&			\\
			&				& \vdots		& \ddots 	\\
\end{bmatrix}.\]
Die Zeilen der Matrix \(U_n\) enthalten alternierend die \(\alpha_i\) mit geraden und ungeraden Indexen.

Die Unterteilung
\[b:= \begin{bmatrix} \vdots \\ b_i \\ \vdots \end{bmatrix} := U_n \begin{bmatrix} \vdots \\ c_k \\ \vdots \end{bmatrix}\]
des Polygons \(c\) berechnet sich daher nach den beiden Regeln
\[b_{2i} = \sum_{k\in \mathbb{Z}} \alpha_{2i-2k}\cdot c_k~~~~~~~~(gerade)\]
und
\[b_{2i+1} = \sum_{k\in \mathbb{Z}} \alpha_{2i+1-2k}\cdot c_k~~~~~~(ungerade),\]
die zur \textit{Unterteilungsgleichung}
\[b_i = \sum_{k\in \mathbb{Z}} \alpha_{i-2k}\cdot c_k, i \in \mathbb{Z}\]
zusammengefasst werden können.


\subsection{Das Symbol}
Die Unterteilungsgleichung kann als Polynommultiplikation aufgefasst werde. Dazu werden die Folge \(b_{\mathbb{Z}}\), \(\alpha_{\mathbb{Z}}\) und \(c_{\mathbb{Z}}\) als symbolische Polygone
\[b(z) := \sum_{i \in \mathbb{Z}} b_i \cdot z^i,\]
\[\alpha(z) := \sum_{i \in \mathbb{Z}} \alpha_i \cdot z^i,\]
\[c(z) := \sum_{i \in \mathbb{Z}} c_i \cdot z^i,\]
dargestellt. Multipliziert man \(\alpha(z)\) und \(c(z^2)\) symbolisch, so erhält man
\[\alpha(z) \cdot c(z^2) = \left(\sum_j \alpha_j\cdot z^j\right) \cdot \left(\sum_k c_k\cdot z^{2k}\right) = b(z),\]
die Laurent-Polynome des unterteilten Polygons.

\paragraph{Folgerung} Die Unterteilungsgleichung hat die Form
\[\beta(z) = \alpha(z)\cdot c(z^2).\]
Das Polynom \(\alpha(z)\) stellt den LR-Algorithmus dar und kann durch ein beliebiges anderes ersetzt werden, um einen anderen Unterteilungsalgorithmus zu erhalten. Es heißt das \textit{Symbol} des Unterteilungsalgorithmus.

\subsubsection{Begrifflichkeiten}
\begin{itemize}
	\item Das Symbol des Unterteilungsalgorithmus heißt \textit{stationäre}, weil immer wieder der selbe Unterteilungsoperator angewendet wird
	\item Der Unterteilungsoperator heißt \textit{linear}, weil er durch eine Matrix dargestellt werden kann
\end{itemize}

\subsubsection{Symbol des LR-Algorithmus}
Das Symbol des \textit{LR-Algorithmus} lässt sich explizit angeben. Mit Hilfe des Binomischen Lehrsatzes\footnote{\url{http://de.wikipedia.org/wiki/Binomischer_Lehrsatz\#Binomischer_Lehrsatz_f.C3.BCr_nat.C3.BCrliche_Exponenten}} erhält man:

\[\alpha_n(z) = \frac{1}{2^n} \sum_{i=0}^{n+1} \binom{n+1}{i} \cdot z^i = \frac{1}{2^n}\cdot (1+z)^{n+1}.\]


\subsection{Das Differenzenschema}
Neben dem Vorwärtsdifferenzenoperator \(\Delta\) gibt es den Rückwärtsdifferenzenoperator \(\nabla\), der ein Polygon \(c:=(c_i)_{i \in \mathbb{Z}}\) auf das Differenzenpolygon
\[\nabla c := (\nabla c_i)_{i \in \mathbb{Z}}\]
der Rückwärtsdifferenzen
\[\nabla c_i := c_i - c_{i-1}\]
abbildet. Er unterscheidet sich bis auf eine Indexverschiebung nicht vom Vorwärtsdifferenzenoperator.

\subsubsection{Matrix zur Berechnung der Rückwärtsdifferenzen}
\[\nabla :=
	\begin{bmatrix}
		\ddots 	& 		& 		&				&		&			\\
				& -1 	& 1		& 				&		&			\\
				& 	 	& -1	& \textbf{1} 	&		&			\\
				&		&		& -1 			& 1		&			\\
				&		&		&				&		& \ddots
	\end{bmatrix}
\]
Die Matrix hat das Symbol \(\nu(z) = 1-z\).

\subsubsection{Folgerung und Definition}
Unterteilt man ein Polygon \(c\) gemäß der Unterteilungsgleichung
\[b(z) = \alpha(z) \cdot c(z^2),\]
genügen die Differenzenpolygone \(b_{\nabla}(z) = \frac{\alpha(z)}{1+z} \cdot c_{\nabla}(z^2)\) und \(c_{\nabla}(z) = (1-z)\cdot c(z)\) der Unterteilungsgleichung
\[b_{\nabla}(z) = \beta(z) \cdot c_{\nabla}(z^2),\]
wobei \(\beta(z) = \frac{\alpha(z)}{1+z}\). Das Symbol \(\beta(z)\) bezeichnet das Differenzenschema zu \(\alpha(z)\).

\paragraph{Bemerkung}
Das Differenzenschema zu \(\alpha(z)\) existiert nur, wenn \(\alpha(z)\) den Faktor \((1+z)\) enhält, bzw. wenn
\[\alpha(-1) = \sum_{i \in \mathbb{Z}} \alpha_{2i} - \sum_{i \in \mathbb{Z}} \alpha_{2i-1} = 0.\]


\subsection{Uniforme Parametrisierung}
Um zu zeigen, dass eine Polygonfolge gegen eine Kurve oder Funktion konvergiert, parametrisiert man die durch den \textit{LR-Algorithmus} erzeugten Polygone.

Sei \(c := \lbrack ...~c_{-1}~c_0~c_1~...\rbrack^T\) ein skalierwertiges Polygon und sei \(d := \lbrack ...~d_{-1}~d_0~d_1~...\rbrack^T\) dessen Differenzenpolygon.

Nach \(k\)-maliger Unterteilung mit dem LR-Algorithmus ergeben sich die Polygone
\[c^k := \begin{bmatrix} u_i^k \\ c_i^k \end{bmatrix}, i \in \mathbb{Z}\]
und
\[d^k := \begin{bmatrix} v_i^k \\ d_i^k \end{bmatrix}, i \in \mathbb{Z}.\]
Wir fassen die Polygone \(c^k\) und \(d^k = \nabla c^k\) als stückweise lineare Funktionen \(c^k(x)\) und \(d^k(x)\) mit den Knoten \(u_i^k\), bzw. \(v_i^k\) auf, so dass
\[c^k(u_i^k) = c_i^k\]
und
\[d^k(v_i^k) = d_i^k.\]

\subsubsection{Folgerung 1}
Die Ableitung \(\frac{d}{dx}c^k(x)\) ist eine stückweise konstante Funktion. Nach Einsetzen und Umformen erhält man
\[\frac{d}{dx}c(x) = \frac{\nabla c_i^k}{\nabla u_i^k} = 2^k d_i^k.\]
Diese skalierten Differenzen werden durch Unterteilung des Differenzenpolygons \(d=\nabla c\) mit \(U_{n-1}\) erzeugt. Dadurch ergibt sich:

\begin{itemize}
	\item \(\frac{1}{2} \cdot U_{n-1}\) ist das Differenzenschema
	\item \(U_{n-1}\) stellt das Ableitungsschema dar
\end{itemize}

\subsubsection{Folgerung 2}
Die stückweise lineare Funktion \(2^k d^k(x)\) approximiert die Ableitung \(\frac{d}{dx} c^k(x)\) und es gilt
\[sup(x \in \mathbb{R})~|~\frac{d}{dx} c^k(x) - 2^k d^k(x)~| \in \mathcal{O}(2^{-k}).\]

Zum Beweis schätzt man die Steigung von \(2^kd^k(x)\) ab und multipliziert sie mit der Länge \(2^{-k}\) der Intervalle.

\subsection{Konvergenz}
Die Funktion \(c^k(x)\) konvergiert gegen eine Funktion \(c_{\infty}(x)\) so, dass
\[sup(x \in \mathbb{R})~|~c_{\infty}(x) - c^k(x)~|~\in \mathcal{O}(4^{-k}).\]

\subsubsection{Folgerung 1}
Die skalierten Differenzpolygone \(2^k d^k(x)\) (Ableitungspolygone) konvergieren gegen
\[\frac{d}{dx} c_{\infty}(x).\]

\subsubsection{Folgerung 2}
Induktiv folgt aus \textit{Folgerung 1}, dass die \(n\)-te Ableitung
\[\frac{d^n}{dx^n} c_{\infty}(x)\]
der Limesfunktion stückweise konstant ist.



\section{Unterteilungsalgorithmen für Flächen}

\subsection{Tensorprodukt}
Ein regelmäßiges, biinfinites Kontrollnetz kann durch eine biinfinite Matrix
\[C = \lbrack c_{i,j} \rbrack_{i,j \in c_{\mathbb{Z}}} = \lbrack c_i \rbrack_{i \in c_{\mathbb{Z}^2}} =: c_{\mathbb{Z}^2}\]
beschrieben werden. Die Matrizen \(U\) und \(V\) zweier stationärer Unterteilungsalgorithmen für Kurven (z.B. der \textit{Lane-Riesenfeld-Algorithmus}) bilden das Kontrollnetz
\[B := b_{\mathbb{Z}^2} := UCV^T,\]
in dem alle Spalten von \(C\) mit \(U\) und dann alle Zeilen von \(UC\) mit \(V\) unterteilt werden. Das Paar \((U,V)\) heißt \textit{Tensorproduktunterteilungsschema} oder kurz \textit{Tepus}.

Die Netze \(U^kC(V^T)^k\) konvergieren gegen eine Fläche, wenn \(U\) und \(V\) konvergente Kurvenunterteilungsalgorithmen sind.


\subsection{Symbole}
Die Matrix \(C=c_{\mathbb{Z}^2}\) hat das Symbol
\[c(x) = \sum_{i \in \mathbb{Z}^2} c_i x^i.\]
Sind \(U\) und \(V\) stationäre Unterteilungsalgorithmen für Kurven mit den Symbolen \(\alpha(x)\) und \(\beta(x)\) hat das unterteilte Netz \(B := b_{\mathbb{Z}^2} := UCV^T\)
das Symbol
\[b(x,y) := \alpha(x) \cdot c(x^2,y^2) \cdot \beta(y).\]
Das Produkt
\[\gamma(x,y) := \alpha(x) \cdot \beta(y)\]
ist das \textit{Symbol des Tepus} \((U,V)\) und die Unterteilungsgleichung ist
\[b(x) = \gamma(x) \cdot c(x^2).\]
Multipliziert man die Unterteilungsgleichung aus, erhält sie die Form
\[b_i = \sum_{j \in \mathbb{Z}^2} \gamma_{i-2j} \cdot c_j.\]

\subsubsection{Beispiel: Das Symbol des Verfeinerungsschemas \((U_0,U_0)\)}
\[\gamma(x,y) = \frac{1}{2} (1+x)(1+y) = \frac{1}{2}
	\begin{bmatrix} 1 & x\end{bmatrix}
	\begin{bmatrix} 1 \\ 1 \end{bmatrix}
	\cdot \begin{bmatrix} 1 & 1 \end{bmatrix}
	\begin{bmatrix} 1 \\ y \end{bmatrix}
\]
\[	= \frac{1}{2}
	\begin{bmatrix} 1 & x \end{bmatrix}
	\begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}
	\begin{bmatrix} 1 \\ y \end{bmatrix}\]

\subsubsection{Beispiel: Das Symbol des Verfeinerungsschemas \((U_1,U_1)\)}
\[\gamma(x,y) = \frac{1}{4} (1+x)^2(1+y)^2 = \frac{1}{4}
	\begin{bmatrix} 1 & x & x^2 \end{bmatrix}
	\begin{bmatrix} 1 \\ 2 \\ 1 \end{bmatrix}
	\cdot \begin{bmatrix} 1 & 2 & 1 \end{bmatrix}
	\begin{bmatrix} 1 \\ y \\ y^2 \end{bmatrix}
\]
\[	= \frac{1}{4}
	\begin{bmatrix} 1 & x & x^2 \end{bmatrix}
	\begin{bmatrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{bmatrix}
	\begin{bmatrix} 1 \\ y \\ y^2 \end{bmatrix}\]

\subsection{Masken}
Sei \(\Gamma := \gamma_{\mathbb{Z}^2}\) eine biinfinite Matrix und sei
\[\gamma(x,y) := \lbrack ...~x^{-1}~x^0~x^1~...\rbrack \cdot \Gamma \cdot \begin{bmatrix} \vdots \\ y^{-1} \\ y^0 \\ y^1 \\ \vdots \end{bmatrix}\]
das Symbol eines Unterteilungsalgorithmus. Die Teilmatrizen
\[\Gamma_i := \lbrack \gamma_{i-2j} \rbrack_{j \in \mathbb{Z}^2}\]
für \(i=(0,0),~(1,0),~(0,1),~(1,1)\) heißen \textit{Masken}. Sie werden graphisch dargestellt, indem die \(\gamma_{i-2j} \ne 0\) an die Punkte eines Teilnetzes geschrieben werden, mt denen sie multipliziert werden. Der resultierende, gewichtete Punkt wird durch einem ausgefüllten, schwarzen Punkt gekennzeichnet.

\subsubsection{Beispiel: Verfeinerungsschema}
Das Verfeinerungsschema \((U_1,U_1)\) erhöht die "`Auflösung"' eines Netzes, in dem zusätzliche Kontrollpunkte in der Mitte von Strecken und Flächen eingefügt werden.

\subsubsection{Beispiel: Mittelungsoperator}
Der Mittelungsoperator \((M,M)\) mit dem Symbol
\[\mu(x,y)= \frac{1}{4}(1+x)(1+y)\]
hat nur eine Maske und interpoliert den Mittelpunkt aus vier Eckpunkten. Die zugehörige Unterteilungsgleichung ist
\[b(x) = \mu(x) \cdot c(x).\]
Die Maske des Mittelungsoperators kann für beliebige Netze und beliebige geometrische Figuren verfeinert werden.


\subsection{Konvergenz}
Wenn sich die Gewichte jeder Maske eines Unterteilungsalgorithmus für regelmäßige Vierecksnetzezu \(1\) summieren und die maximale Kantenlänge \(k\)-mal unterteilter Netze für \(k \rightarrow \infty\) gegen \(0\) geht, konvergieren die Netze gegen eine stetige Fläche.

Unterteilungsalgorithmen für regelmäßige Dreiecksnetze können als Unterteilungsalgorithmen für regelmäßige Vierecksnetze aufgefasst werden.



\section{Textsuche}
Im Folgenden bezeichnet \(A\) ein Alphabet, \(t = t_1,...,t_n \in A^n\) einen Text und \(s = s_1,...s_m \in A^m\) einen Suchtext, für den bestimmt werden soll, ob er in \(t\) und gegebenenfalls an welcher Stelle er auftritt. Es wird vorausgesetzt, dass \(m < n\).

\subsection{Naive Textsuche}
\input{algo2/algo_naive-textsuche}
Der Aufwand für diesen Algorithmus liegt im schlechtesten Fall in \(\Theta(m\cdot n)\).


\subsection{Der Algorithmus von Boyer und Moore}
Der Algorithmus von Boyer und Moore erweitert die \textit{Naive Suche} um die \textit{Vorkommens- und Suffixheuristiken}.

Um das Vorgehen effizient zu gestalten, wird für beide Heuristiken in einem Vorverarbeitungsschritt jeweils eine Sprungtabelle errechnet. Die Sprungtabelle für die Bad-Character-Heuristik enthält für jedes im Suchmuster vorkommende Zeichen den Abstand von der Position des letzten Vorkommens im Suchmuster bis zum Ende des Suchmusters.

Die Tabelle für die Good-Suffix-Heuristik enthält für jedes Teilmuster (von hinten aus gesehen) den Abstand vom Ende des Musters, ab dem es wieder im Muster vorkommt.\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus}}

\subsubsection{Die Vorkommensheuristik (Bad-Character-Heuristik)}
Im Algorithmus \textit{NAIVE-SUCHE} wird \(i\) um jeweils \(1\) erhöht, d.h. der Suchtext wird verschoben. Man kann \(i\) oft um mehr als \(1\) erhöhen, wenn man für jedes Zeichen \(a \in A\) weiß, an welcher Stelle \(\nu\) es in \(s\) zuletzt vorkommt. Dies wird durch die \textit{Vorkommensfunktion} beschrieben:
\[\nu \rightarrow \{0,...,m\}\]
\[a \mapsto \nu(a),\]
wobei
\[\nu(a) := min\{k~|~a \notin s_{k+1},...,s_m~und~(a=s_k \lor k=0)\}\]

\paragraph{Vorgehen anschaulich}
Die Beschreibung entstammt der deutschen Wikipedia\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus}}.
\begin{itemize}
	\item Muster wird linksbündig unter den Text geschrieben und von rechts nach links mit dem Text verglichen
	\item Sobald ein Mismatch auftritt, wird berechnet wie weit das Suchmuster nach rechts verschoben werden kann, wobei das Zeichen des Texts gilt
	\item Existiert der entsprechende Buchstabe nicht im Muster, kann um die ganze Länge des Musters verschoben werden
\end{itemize}
Die Funktion \(\nu\) kann mit einem Aufwand in \(\mathcal{O}(|A|+m)\) vorberechnet werden.


\subsubsection{Die Suffix-Heuristik (Good-Suffix-Heuristik)}
Mit einer zweiten Heuristik lässt sich die Laufzeit der \textit{Naiven Suche} noch weiter reduzieren, so dass sie in \(\mathcal{O}(n+m)\) liegt.

\subsubsection{Vorgehen anschaulich}
Stimmt beim Vergleich des Musters mit dem Text von rechts nach links ein Suffix des Musters mit dem Text überein und tritt danach aber ein Mismatch auf, wird das Muster soweit nach rechts geschoben, bis ein Teilwort des Musters wieder auf das Suffix passt. Existiert das Suffix kein zweites Mal im Muster, wird das Muster um seine volle Länge nach rechts verschoben\footnote{\url{http://de.wikipedia.org/wiki/Boyer-Moore-Algorithmus\#Algorithmus}}.

\subsubsection{Berechnung der Suffixvorkommensfunktion}
Die Heuristik berechnet für jedes Zeichen des Suchworts, wie weit von diesem aus verschoben werden kann. Grundlage ist dabei die Gamma-Funktion, welche für jedes Zeichen des Suchworts die Länge des größten, echten Präsuffixes angibt.

\paragraph{Definition Präsuffix}
Ein Präfix eines Wortes \(w\), das zugleich ein Suffix von \(w\) ist, nennen wir Präsuffix von \(w\) und bezeichnen das größte echte Präsuffix mit \(geps(w)\).

Sei \(w_j := s_{j+1},...,s_m\) und \(\gamma(j) := |gpes(w_j)|\). Die \(gpes\)-Länge ist für \(j=0,...,m-1\) definiert, insbesondere ist \(\gamma(m-1)=0\).

\subsubsection{Berechnung von \(\gamma\)}
Die Funktion berechnet für jedes Zeichen des Suchworts die Länge des größten, echten Präsuffixes.

\(gpes(w_{i-1})\) verkürzt um \(s_i\) ist ebenfalls Präsuffix von \(w_i\), daher gilt
\[\gamma(i-1) -1 \leq \gamma(i).\]
Falls \(j := m-\gamma(i)\) und \(s_i \ne s_j\), ist \(geps(w_{i-1})\) verkürzt um \(s_i\) auch Präsuffix von \(w_j\). Daraus folgt der Algorithmus:
\\\\
\input{algo2/algo_boyer-moore_gamma}

\subsubsection{Aufwand von \(\gamma\)}
Der Aufwand für \(\gamma\) liegt in \(\mathcal{O}(m)\), denn
\begin{itemize}
	\item \(j\) wird in Zeile \(5\) erhöht
	\item und in Zeile \(3\) wegen Zeile \(9\) jeweils um \(1\) größer.
\end{itemize}
Da \(j\) anfangs \(m\) ist und immer \(\leq m\) bleibt, wird \(j\) höchstens \((m-1)\)-mal in Schritt \(5\) erhöht.

\paragraph{Berechnung von \(\sigma\)}
Die \(\sigma\)-Funktion gibt unmittelbar an, wie weit verschoben werden kann.
\text{}\\
\input{algo2/algo_boyer-moore_sigma}
It \(\gamma\) bekannt, ist die Laufzeit von \(\sigma\) linear in \(m\).

\subsubsection{Bemerkung}
In der Praxis trägt die Suffixheuristik kaum zu Beschleunigung bei. Sie verhindert lediglich eine worst-case-Laufzeit in \(\Theta(m\cdot n)\).

\subsubsection{Der Algorithmus}
\input{algo2/algo_boyer-moore}
